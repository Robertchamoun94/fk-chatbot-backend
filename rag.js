import OpenAI from "openai";
import weaviate from "weaviate-ts-client";
import dotenv from "dotenv";
import fs from "fs";
dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const client = weaviate.client({
  scheme: "https",
  host: process.env.WEAVIATE_HOST,
  apiKey: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY),
});

const indexName = "FK_Document";

// Moderna modellnamn (kan overrideas via .env)
const CHAT_MODEL = process.env.OPENAI_CHAT_MODEL || "gpt-4o-mini";
const EMBEDDING_MODEL = process.env.OPENAI_EMBED_MODEL || "text-embedding-3-small";

export async function askRAG(query) {
  try {
    console.log("üîç Skickar fr√•ga till OpenAI f√∂r embedding...");
    const embeddingResponse = await openai.embeddings.create({
      model: EMBEDDING_MODEL,
      input: query,
    });

    const queryEmbedding = embeddingResponse.data[0].embedding;

    console.log("üß† Fr√•gar Weaviate med vektor...");
    const result = await client.graphql
      .get()
      .withClassName(indexName)
      .withFields("text _additional {certainty}")
      .withNearVector({
        vector: queryEmbedding,
        certainty: 0.6,
      })
      .withLimit(5)
      .do();

    const docs = result?.data?.Get?.[indexName] || [];

    // üîÅ Om vi inte f√•r n√•gra relevanta tr√§ffar ‚Üí fallback till GPT direkt
    if (docs.length === 0) {
      console.warn("‚ö†Ô∏è Inga tr√§ffar i Weaviate, anv√§nder fallback till GPT direkt...");
      return await fallbackToGPT(query);
    }

    const context = docs.map((doc) => doc.text).join("\n---\n");

    const prompt = `
Du √§r en hj√§lpsam AI-assistent som svarar med korrekt information fr√•n F√∂rs√§kringskassan.
Anv√§nd bara fakta fr√•n texten nedan n√§r du besvarar fr√•gan. Om svaret inte finns i texten, svara "Jag vet tyv√§rr inte".

TEXT:
${context}

FR√ÖGA: ${query}
SVAR:
    `.trim();

    console.log("üí¨ Skickar prompt till GPT...");
    const chatResponse = await openai.chat.completions.create({
      model: CHAT_MODEL,
      messages: [{ role: "user", content: prompt }],
      temperature: 0.2,
    });

    return chatResponse.choices?.[0]?.message?.content?.trim() || "Jag vet tyv√§rr inte.";
  } catch (error) {
    console.error(
      "‚ùå Fel i RAG-s√∂kning:",
      error?.response?.data?.error?.message || error.message
    );
    return "Ett fel uppstod vid h√§mtning av svar fr√•n GPT.";
  }
}

async function fallbackToGPT(query) {
  try {
    const fallbackPrompt = `
Du √§r en generell AI-assistent. Besvara fr√•gan s√• gott du kan, √§ven om du inte har tillg√•ng till extern kontext.
FR√ÖGA: ${query}
SVAR:
    `.trim();

    const chatResponse = await openai.chat.completions.create({
      model: CHAT_MODEL,
      messages: [{ role: "user", content: fallbackPrompt }],
      temperature: 0.7,
    });

    return chatResponse.choices?.[0]?.message?.content?.trim() || "Jag vet tyv√§rr inte.";
  } catch (error) {
    console.error(
      "‚ùå Fel i fallback till GPT:",
      error?.response?.data?.error?.message || error.message
    );
    return "Ett fel uppstod vid fallback-svar fr√•n GPT.";
  }
}
