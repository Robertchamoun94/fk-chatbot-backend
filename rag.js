import OpenAI from "openai";
import weaviate from "weaviate-ts-client";
import dotenv from "dotenv";
import fs from "fs";
dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const client = weaviate.client({
  scheme: "https",
  host: process.env.WEAVIATE_HOST,
  apiKey: new weaviate.ApiKey(process.env.WEAVIATE_API_KEY),
});

const indexName = "FK_Document";

// Moderna modellnamn (kan overrideas via .env)
const CHAT_MODEL = process.env.OPENAI_CHAT_MODEL || "gpt-4o-mini";
const EMBEDDING_MODEL = process.env.OPENAI_EMBED_MODEL || "text-embedding-3-small";

// Toggle: s√§tt RAG_DISABLED=true i .env f√∂r att hoppa √∂ver Weaviate helt
const RAG_DISABLED = String(process.env.RAG_DISABLED).toLowerCase() === "true";

export async function askRAG(query) {
  // Snabbt demo-l√§ge utan RAG
  if (RAG_DISABLED) {
    console.warn("RAG_DISABLED=true ‚Äî hoppar √∂ver vektors√∂k och anv√§nder GPT direkt.");
    return await fallbackToGPT(query);
  }

  try {
    console.log("üîç Skickar fr√•ga till OpenAI f√∂r embedding...");
    const embeddingResponse = await openai.embeddings.create({
      model: EMBEDDING_MODEL,
      input: query,
    });
    const queryEmbedding = embeddingResponse.data[0].embedding;

    console.log("üß† Fr√•gar Weaviate med vektor...");
    let result;
    try {
      // Versionss√§ker GraphQL: be bara om 'text' (inga _additional-f√§lt)
      result = await client.graphql
        .get()
        .withClassName(indexName)
        .withFields("text")
        .withNearVector({ vector: queryEmbedding }) // ingen 'certainty' (kan skilja mellan versioner)
        .withLimit(5)
        .do();
    } catch (weavErr) {
      console.error("‚ùå Weaviate-fel:", weavErr?.message || weavErr);
      // Forts√§tt √§nd√• med GPT s√• att demo fungerar
      return await fallbackToGPT(query);
    }

    const docs = result?.data?.Get?.[indexName] || [];
    if (docs.length === 0) {
      console.warn("‚ö†Ô∏è Inga tr√§ffar i Weaviate, anv√§nder fallback till GPT direkt...");
      return await fallbackToGPT(query);
    }

    const context = docs.map((doc) => doc.text).join("\n---\n");

    const prompt = `
Du √§r en hj√§lpsam AI-assistent som svarar med korrekt information fr√•n F√∂rs√§kringskassan.
Anv√§nd bara fakta fr√•n TEXT nedan n√§r du besvarar fr√•gan. Om svaret inte finns i texten, svara exakt: "Jag vet tyv√§rr inte".

TEXT:
${context}

FR√ÖGA: ${query}
SVAR:
    `.trim();

    console.log("üí¨ Skickar prompt till GPT...");
    const chatResponse = await openai.chat.completions.create({
      model: CHAT_MODEL,
      messages: [{ role: "user", content: prompt }],
      temperature: 0.2,
    });

    return chatResponse.choices?.[0]?.message?.content?.trim() || "Jag vet tyv√§rr inte.";
  } catch (error) {
    console.error(
      "‚ùå Fel i RAG-s√∂kning:",
      error?.response?.data?.error?.message || error.message
    );
    // Svara √§nd√•
    return await fallbackToGPT(query);
  }
}

async function fallbackToGPT(query) {
  try {
    const fallbackPrompt = `
Du √§r en generell AI-assistent. Besvara fr√•gan s√• gott du kan, √§ven utan extern kontext.
FR√ÖGA: ${query}
SVAR:
    `.trim();

    const chatResponse = await openai.chat.completions.create({
      model: CHAT_MODEL,
      messages: [{ role: "user", content: fallbackPrompt }],
      temperature: 0.4,
    });

    return chatResponse.choices?.[0]?.message?.content?.trim() || "Jag vet tyv√§rr inte.";
  } catch (error) {
    console.error(
      "‚ùå Fel i fallback till GPT:",
      error?.response?.data?.error?.message || error.message
    );
    return "Ett fel uppstod vid fallback-svar fr√•n GPT.";
  }
}
