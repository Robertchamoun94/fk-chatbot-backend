from chromadb import PersistentClient
from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction
import os
import openai

def semantic_search_full(query, top_k=5):
    # ğŸ”— Anslut till din sparade Chroma-index
    client = PersistentClient(path="data/chroma_index")

    # ğŸ§  Ladda vektorindex + embeddings
    collection = client.get_or_create_collection(
        name="fk-full",
        embedding_function=OpenAIEmbeddingFunction(api_key=os.getenv("OPENAI_API_KEY"))
    )

    # ğŸ” SÃ¶k liknande dokument
    results = collection.query(query_texts=[query], n_results=top_k)
    docs = results.get("documents", [[]])[0]
    context = "\n\n".join(docs)

    # ğŸ§¾ SÃ¤tt upp GPT-systeminstruktion
    system_instruction = (
        "Du Ã¤r en expert pÃ¥ FÃ¶rsÃ¤kringskassans regler. "
        "Svara endast med korrekt och faktabaserad information frÃ¥n kontexten nedan. "
        "Om frÃ¥gan inte kan besvaras med informationen â€“ sÃ¤g att du inte vet."
    )

    # ğŸ§  Anropa GPT med frÃ¥gan + kontext
    openai.api_key = os.getenv("OPENAI_API_KEY")
    completion = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": system_instruction},
            {"role": "user", "content": f"FrÃ¥ga: {query}\n\nKONTEKST:\n{context}"}
        ],
        temperature=0
    )

    return completion.choices[0].message.content
